## Abstract for SIAM-PNW 2017

Highly technical industries such as aerospace require fluid simulations of increasing fidelity to develop next-generation technologies. Since these simulations consume more resources than individual workstations can reasonably accommodate, they are generally performed on clusters with several multi-core CPUs. As accelerating processor technologies, notably general purpose graphics processing units (GPGPU), have developed rapidly in the last decade, they have become more common in large clusters, and can have a dramatic effect on their performance. As clusters grow in complexity, computational power, and physical size, the performance of applications that require regular communication between nodes is limited by the cost determined by the system's latency and bandwidth. Bandwidth is the amount of memory that can be communicated per unit of time, and latency is the fixed cost of a communication event -- the travel time of the first byte over the connection. Explicit PDEs solutions that are naively decomposed on a cluster require internode communication of small data packets at every time-step.  The frequency of these communication events renders their fixed cost, latency, a significant barrier to performance.  The swept rule is a domain decomposition scheme that arranges computation to avoid communication events and diminish the overall latency cost of a simulation.  The swept rule continues the computation on an individual node whose stencil contains locally available values.  This way the simulation may continue until no spatial points have available stencils and the required values are passed to the neighboring node in a single communication event.  In this study, we apply this scheme to the Euler equations for incompressible flow in one dimension using Sod’s shock tube problem on a cluster at Oregon State University with one GPGPU.  We study the effect of the ratio of CPU to GPU work and the overall performance of the application compared to a naïve scheme.